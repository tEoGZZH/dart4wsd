{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3fb9f76-5186-47ad-8fce-10824d796cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from util import load_balls, preprocess_data\n",
    "from dataset import nballDataset\n",
    "from model import nballBertNorm, nballBertDirection\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d7c42e-6855-45a2-9e06-7932afbaf42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading balls....\n",
      "43667 balls are loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_semcor_path = {\n",
    "    \"xml\":'../data/WSD_Evaluation_Framework/Training_Corpora/Semcor/semcor.data.xml',\n",
    "    \"gold_key\":'../data/WSD_Evaluation_Framework/Training_Corpora/Semcor/semcor.gold.key.txt',}\n",
    "\n",
    "eval_all_path = {\n",
    "    \"xml\":'../data/WSD_Evaluation_Framework/Evaluation_Datasets/ALL/ALL.data.xml',\n",
    "    \"gold_key\":'../data/WSD_Evaluation_Framework/Evaluation_Datasets/ALL/ALL.gold.key.txt',}\n",
    "\n",
    "nball_path = '../data/sample_entity/nball.txt'\n",
    "\n",
    "nball = load_balls(nball_path)\n",
    "train_semcor, lemma_pair = preprocess_data(train_semcor_path, nball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d48327-7a4d-4d1c-86d4-328cdcfedb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>word</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>lemma_idx</th>\n",
       "      <th>formatted_sense_id</th>\n",
       "      <th>sense_idx</th>\n",
       "      <th>sense_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>objective</td>\n",
       "      <td>objectives</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>4849</td>\n",
       "      <td>aim.n.02</td>\n",
       "      <td>5720</td>\n",
       "      <td>[5720, 11008]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benefit</td>\n",
       "      <td>benefit</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>894</td>\n",
       "      <td>benefit.n.01</td>\n",
       "      <td>20775</td>\n",
       "      <td>[1007, 14577, 20775]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service</td>\n",
       "      <td>service</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>8210</td>\n",
       "      <td>service.n.05</td>\n",
       "      <td>11463</td>\n",
       "      <td>[10367, 10754, 10769, 10898, 11463, 12006, 122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>program</td>\n",
       "      <td>program</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>3824</td>\n",
       "      <td>program.n.02</td>\n",
       "      <td>4552</td>\n",
       "      <td>[4552, 8006, 9367, 11149]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>giveaway</td>\n",
       "      <td>giveaway</td>\n",
       "      <td>Have you permitted it to become a giveaway pro...</td>\n",
       "      <td>9705</td>\n",
       "      <td>giveaway.n.01</td>\n",
       "      <td>20555</td>\n",
       "      <td>[12752, 20555]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lemma        word                                      sentence_text  \\\n",
       "0  objective  objectives  How long has it been since you reviewed the ob...   \n",
       "1    benefit     benefit  How long has it been since you reviewed the ob...   \n",
       "2    service     service  How long has it been since you reviewed the ob...   \n",
       "3    program     program  How long has it been since you reviewed the ob...   \n",
       "4   giveaway    giveaway  Have you permitted it to become a giveaway pro...   \n",
       "\n",
       "   lemma_idx formatted_sense_id  sense_idx  \\\n",
       "0       4849           aim.n.02       5720   \n",
       "1        894       benefit.n.01      20775   \n",
       "2       8210       service.n.05      11463   \n",
       "3       3824       program.n.02       4552   \n",
       "4       9705      giveaway.n.01      20555   \n",
       "\n",
       "                                         sense_group  \n",
       "0                                      [5720, 11008]  \n",
       "1                               [1007, 14577, 20775]  \n",
       "2  [10367, 10754, 10769, 10898, 11463, 12006, 122...  \n",
       "3                          [4552, 8006, 9367, 11149]  \n",
       "4                                     [12752, 20555]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30165\n",
      "43667\n"
     ]
    }
   ],
   "source": [
    "# Problem about lemma\n",
    "display(train_semcor.head())\n",
    "print(len(lemma_pair))\n",
    "print(len(nball.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc006f90-7c18-46f0-a73f-9b4b8e0a2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading nball embeddings\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sense_labels = list(nball.keys())\n",
    "nball_embeddings = [nball[label].center for label in sense_labels]\n",
    "nball_norms = [nball[label].distance for label in sense_labels]\n",
    "nball_radius = [nball[label].radius for label in sense_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0dc3d75-4bf7-419b-9943-0af8f01683f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest 10 elements in nball_norms: [1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0, 1030316.9252039694, 1030316.9252039694, 1030316.9252039694]\n",
      "Largest 10 elements in nball_norms: [9.271626654035237e+260, 9.272199640406976e+260, 9.273105763720828e+260, 9.276812880845236e+260, 9.291212959815524e+260, 9.391083976630392e+260, 9.421969111692328e+260, 9.481569869909228e+260, 9.610572799981588e+260, 9.788260408452398e+260]\n",
      "Smallest 10 elements in nball_radius: [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.00010303169252039694, 0.00010303169252039694, 0.00010303169252039694]\n",
      "Largest 10 elements in nball_radius: [1.592188358137684e+259, 1.6796639919064024e+259, 2.0786414176209017e+259, 5.092086803778581e+259, 1.0510336007745004e+260, 1.1778868338387624e+260, 1.994060113116811e+260, 3.38293997519766e+260, 5.766343679988953e+260, 9.788260408452398e+260]\n"
     ]
    }
   ],
   "source": [
    "# Data checking:\n",
    "# Sorting the lists\n",
    "nball_norms_sorted = sorted(nball_norms)\n",
    "nball_radius_sorted = sorted(nball_radius)\n",
    "\n",
    "# Getting the smallest 10 from each list\n",
    "smallest_10_norms = nball_norms_sorted[:10]\n",
    "smallest_10_radius = nball_radius_sorted[:10]\n",
    "\n",
    "# Getting the largest 10 from each list\n",
    "largest_10_norms = nball_norms_sorted[-10:]\n",
    "largest_10_radius = nball_radius_sorted[-10:]\n",
    "\n",
    "# Printing the results\n",
    "print(\"Smallest 10 elements in nball_norms:\", smallest_10_norms)\n",
    "print(\"Largest 10 elements in nball_norms:\", largest_10_norms)\n",
    "\n",
    "print(\"Smallest 10 elements in nball_radius:\", smallest_10_radius)\n",
    "print(\"Largest 10 elements in nball_radius:\", largest_10_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3386c9-4b8a-4844-8b9d-003de531fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap as tensor\n",
    "nball_embeddings = torch.tensor(np.array(nball_embeddings), dtype=torch.float32).to(device)\n",
    "nball_norms = torch.tensor(np.array(nball_norms), dtype=torch.float32).to(device)\n",
    "nball_radius = torch.tensor(np.array(nball_radius), dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f64353-5757-4daf-9945-9c8afeaf718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model list\n",
    "bert_models = {\"BERT-Base\": [\"bert-base-uncased\", 768], #768, 12L, 12A\n",
    "               \"BERT-Large\": [\"bert-large-uncased\", 1024], #1024, 24L, 16A\n",
    "               \"BERT-Medium\": [\"google/bert_uncased_L-8_H-512_A-8\", 512], #512, 8L, 8A\n",
    "               \"BERT-Small\": [\"google/bert_uncased_L-4_H-256_A-4\", 256], #256, 4L, 4A\n",
    "               \"BERT-Mini\": [\"google/bert_uncased_L-4_H-128_A-2\", 128],#128, 4L, 2A\n",
    "               \"BERT-Tiny\": [\"google/bert_uncased_L-2_H-128_A-2\", 128]}#128, 2L, 2A\n",
    "\n",
    "max_length = 512\n",
    "batch_size = 32\n",
    "model_url = bert_models[\"BERT-Small\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec50671e-858d-49a7-9da7-7cf63aaa234e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sentences...\n",
      "Tokenizing finished.\n",
      "Calculating word indices...\n",
      "Tokenizing finished.\n"
     ]
    }
   ],
   "source": [
    "dataset_train = nballDataset(train_semcor, nball, model_url, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2e867ed-6983-46a3-9703-3166b90730b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e768faf8-a3dc-487a-9015-0717861edbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, scheduler, num_epochs, mode):\n",
    "    last_loss = 0\n",
    "    if mode == \"norm\":\n",
    "        loss_fn = log_cosh_loss\n",
    "    elif mode == \"direction\":\n",
    "        loss_fn = nn.CosineEmbeddingLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=True, position=0)\n",
    "        for batch in progress_bar:\n",
    "            # Unpack batch and send to device\n",
    "            batch_input_ids, batch_attention_masks, batch_word_indices, \\\n",
    "            batch_sense_indices, _, _ = [b.to(device) for b in batch]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # Forward pass\n",
    "            output = model(input_ids=batch_input_ids, attention_mask=batch_attention_masks, \\\n",
    "                            word_index=batch_word_indices).squeeze()\n",
    "\n",
    "            # print(output)\n",
    "            if mode == \"norm\":\n",
    "                batch_norms = nball_norms[batch_sense_indices]\n",
    "                loss = loss_fn(output, batch_norms * 1e-5)\n",
    "            elif mode == \"direction\":\n",
    "                labels = torch.ones(output.size(0), device=device)\n",
    "                batch_senses = nball_embeddings[batch_sense_indices]\n",
    "                loss = loss_fn(output, batch_senses, labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Logging average metrics per epoch\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        improvement = (last_loss - total_loss) / len(dataloader) if last_loss != 0 else 0\n",
    "        print(f'Epoch {epoch + 1}, Avg Loss: {avg_loss}, Improvement: {improvement}')\n",
    "        last_loss = total_loss\n",
    "\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f992cfad-b346-46c7-9e26-3d80ebc406db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|                                                                             | 0/2506 [00:00<?, ?it/s]D:\\Anaconda\\envs\\dart4wsd\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Epoch 1/50: 100%|████████████████████████████████████████████████████████| 2506/2506 [01:58<00:00, 21.18it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: nan, Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|████████████████████████████████████████████████████████| 2506/2506 [02:00<00:00, 20.83it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Avg Loss: nan, Improvement: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|████████████████████████████████████████████████████████| 2506/2506 [02:08<00:00, 19.54it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Avg Loss: nan, Improvement: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|████████████████████████████████████████████████████████| 2506/2506 [02:03<00:00, 20.35it/s, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Avg Loss: nan, Improvement: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50:  82%|██████████████████████████████████████████████          | 2062/2506 [01:47<00:23, 19.27it/s, loss=nan]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m optimizer_norm \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam([\n\u001b[0;32m      9\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: model_norm\u001b[38;5;241m.\u001b[39mparameters()}\n\u001b[0;32m     10\u001b[0m ], lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m)\n\u001b[0;32m     11\u001b[0m scheduler_norm \u001b[38;5;241m=\u001b[39m StepLR(optimizer_norm, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m train(model\u001b[38;5;241m=\u001b[39mmodel_norm, \\\n\u001b[0;32m     14\u001b[0m       dataloader\u001b[38;5;241m=\u001b[39mdataloader_train,\\\n\u001b[0;32m     15\u001b[0m       optimizer\u001b[38;5;241m=\u001b[39moptimizer_norm,\\\n\u001b[0;32m     16\u001b[0m       scheduler\u001b[38;5;241m=\u001b[39mscheduler_norm,\\\n\u001b[0;32m     17\u001b[0m       num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, \\\n\u001b[0;32m     18\u001b[0m       mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, optimizer, scheduler, num_epochs, mode)\u001b[0m\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m output \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39mbatch_input_ids, attention_mask\u001b[38;5;241m=\u001b[39mbatch_attention_masks, \\\n\u001b[0;32m     20\u001b[0m                 word_index\u001b[38;5;241m=\u001b[39mbatch_word_indices)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# print(output)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\dart4wsd\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\dart4wsd\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\OtherProject\\dart4wsd\\notebooks\\../src\\model.py:18\u001b[0m, in \u001b[0;36mnballBertNorm.forward\u001b[1;34m(self, input_ids, attention_mask, word_index)\u001b[0m\n\u001b[0;32m     16\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m     17\u001b[0m word_embeddings \u001b[38;5;241m=\u001b[39m hidden_states[\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(word_index)), word_index]\n\u001b[1;32m---> 18\u001b[0m projected_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection(word_embeddings)\n\u001b[0;32m     19\u001b[0m norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregressor(projected_output)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m norm\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\dart4wsd\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1675\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1666\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[0;32m   1670\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[0;32m   1674\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[1;32m-> 1675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m   1677\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train norm\n",
    "def log_cosh_loss(norm_u, norm_v):\n",
    "    return torch.log(torch.cosh(norm_u - norm_v)).mean()\n",
    "\n",
    "output_dim = 160\n",
    "model_norm = nballBertNorm(model_url, output_dim).to(device)\n",
    "loss_fn_norm = log_cosh_loss\n",
    "optimizer_norm = optim.Adam([\n",
    "    {'params': model_norm.parameters()}\n",
    "], lr=2e-5)\n",
    "scheduler_norm = StepLR(optimizer_norm, step_size=50, gamma=0.1)\n",
    "\n",
    "train(model=model_norm, \\\n",
    "      dataloader=dataloader_train,\\\n",
    "      optimizer=optimizer_norm,\\\n",
    "      scheduler=scheduler_norm,\\\n",
    "      num_epochs=50, \\\n",
    "      mode=\"norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f1745ee-ed0f-46b6-a6c5-ded7af1b8c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.40it/s, loss=0.656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 0.7961865121668036, Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.89it/s, loss=0.422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Avg Loss: 0.5248720320788297, Improvement: 0.2713144800879739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.52it/s, loss=0.268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Avg Loss: 0.331489080732519, Improvement: 0.1933829513463107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.91it/s, loss=0.176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Avg Loss: 0.21626012433658948, Improvement: 0.1152289563959295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.26it/s, loss=0.116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Avg Loss: 0.1408380540934476, Improvement: 0.07542207024314186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|█████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.19it/s, loss=0.0778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Avg Loss: 0.09525820680639961, Improvement: 0.045579847287047996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|█████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.94it/s, loss=0.0576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Avg Loss: 0.06695131280205467, Improvement: 0.02830689400434494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|█████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.72it/s, loss=0.0456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Avg Loss: 0.05028599839318882, Improvement: 0.01666531440886584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|█████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.36it/s, loss=0.0362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Avg Loss: 0.0400114387951114, Improvement: 0.010274559598077427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.38it/s, loss=0.0338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Avg Loss: 0.03469809449531815, Improvement: 0.005313344299793243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.89it/s, loss=0.0293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Avg Loss: 0.030054971575737, Improvement: 0.004643122919581153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.70it/s, loss=0.0268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Avg Loss: 0.027172402902082962, Improvement: 0.002882568673654036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.73it/s, loss=0.0249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Avg Loss: 0.025503649630329826, Improvement: 0.0016687532717531378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.56it/s, loss=0.0222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Avg Loss: 0.023086079650304535, Improvement: 0.0024175699800252914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.61it/s, loss=0.0211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Avg Loss: 0.022033502771095795, Improvement: 0.001052576879208738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.73it/s, loss=0.0189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Avg Loss: 0.020354048602960327, Improvement: 0.0016794541681354697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.08it/s, loss=0.0186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Avg Loss: 0.019648710265755653, Improvement: 0.000705338337204673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.86it/s, loss=0.0193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Avg Loss: 0.019208111715587704, Improvement: 0.0004405985501679507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.26it/s, loss=0.0172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Avg Loss: 0.017973837358030407, Improvement: 0.0012342743575572968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.45it/s, loss=0.0171]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Avg Loss: 0.017240411686626347, Improvement: 0.0007334256714040583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train direction\n",
    "model_d = nballBertDirection(model_url, output_dim).to(device)\n",
    "optimizer_d = optim.Adam([\n",
    "    {'params': model_d.parameters()}\n",
    "], lr=2e-5)\n",
    "scheduler_d = StepLR(optimizer_d, step_size=50, gamma=0.1)\n",
    "\n",
    "train(model=model_d, \\\n",
    "      dataloader=dataloader_train,\\\n",
    "      optimizer=optimizer_d,\\\n",
    "      scheduler=scheduler_d,\\\n",
    "      num_epochs=20, \\\n",
    "      mode=\"direction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2a2b78a-eb04-42cd-a76c-82929d1e46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tree structure\n",
    "wsChildrenFile = '../data/sample_mammal/wsChildren.txt'\n",
    "def load_tree(wsChildrenFile = None):\n",
    "    \"\"\"\n",
    "    Read the file of word2vec and wsChildren, save them into dictionary\n",
    "\n",
    "    :param word2vecFile:path of word2vecFile\n",
    "    :param wsChildrenFile:path of wsChildrenFile\n",
    "    :return:two dictionary of word2vecDic and wsChildrenDic\n",
    "    \"\"\"\n",
    "    wsChildrenDic = dict()\n",
    "    with open(wsChildrenFile, 'r') as chfh:\n",
    "        for ln in chfh:\n",
    "            wlst = ln[:-1].split()\n",
    "            wsChildrenDic[wlst[0]] = wlst[1:]\n",
    "    return wsChildrenDic\n",
    "\n",
    "tree = load_tree(wsChildrenFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "775c3d70-8134-4581-b211-e62aba619080",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index = {label: idx for idx, label in enumerate(sense_labels)}\n",
    "index_to_label = {idx: label for idx, label in enumerate(sense_labels)}\n",
    "\n",
    "def predict_with_tree(tree, output_emb, candidate_indices, candidate_norms, candidate_directions, candidate_radii, nball_norms, nball_embeddings, nball_radius, index_to_label, label_to_index):\n",
    "    current_nodes = [index_to_label[idx] for idx in candidate_indices]\n",
    "    visited_nodes = set()\n",
    "    \n",
    "    while current_nodes:\n",
    "        distances = [F.pairwise_distance(output_emb.unsqueeze(0), (cand_dir * cand_norm.unsqueeze(-1)).unsqueeze(0)).item()\n",
    "                     for cand_dir, cand_norm in zip(candidate_directions, candidate_norms)]\n",
    "        within_radius_indices = [idx for idx, (distance, radius) in enumerate(zip(distances, candidate_radii)) if distance <= radius.item()]\n",
    "        \n",
    "        if within_radius_indices:\n",
    "            return label_to_index[current_nodes[within_radius_indices[0]]]  # Return the first one within the radius\n",
    "        \n",
    "        visited_nodes.update(current_nodes)  # Add current nodes to visited set\n",
    "        \n",
    "        # Move to the parent nodes, avoiding revisiting nodes\n",
    "        parent_nodes = set()\n",
    "        for node in current_nodes:\n",
    "            for parent, children in tree.items():\n",
    "                if node in children and parent not in visited_nodes:\n",
    "                    parent_nodes.add(parent)\n",
    "        \n",
    "        current_nodes = list(parent_nodes)\n",
    "        candidate_norms = [nball_norms[label_to_index[node]] * 1e-5 for node in current_nodes]\n",
    "        candidate_directions = [nball_embeddings[label_to_index[node]] for node in current_nodes]\n",
    "        candidate_radii = [nball_radius[label_to_index[node]] for node in current_nodes]\n",
    "    \n",
    "    return None  # Return None if no suitable candidate is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17cfc072-e223-4298-b8de-b2e3fb648cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "def evaluation(model_n, model_d, dataloader):\n",
    "    model_n.eval()\n",
    "    model_d.eval()\n",
    "\n",
    "    loss_fn_n = log_cosh_loss\n",
    "    loss_fn_d = nn.CosineEmbeddingLoss()\n",
    "\n",
    "    loss_n = 0.0\n",
    "    loss_d = 0.0\n",
    "    accuracy = 0.0\n",
    "    correct_predictions = 0\n",
    "    pred_indices = {}\n",
    "    size = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluation\", leave=True, position=0):\n",
    "            batch_input_ids, batch_attention_masks, batch_word_indices, \\\n",
    "            batch_sense_indices, batch_lemma_indices, batch_idices = [b.to(device) for b in batch]\n",
    "\n",
    "            # Forward pass\n",
    "            norms = model_n(input_ids=batch_input_ids, attention_mask=batch_attention_masks, \\\n",
    "                            word_index=batch_word_indices).squeeze()\n",
    "            directions = model_d(input_ids=batch_input_ids, attention_mask=batch_attention_masks, \\\n",
    "                                 word_index=batch_word_indices).squeeze()\n",
    "\n",
    "            target_norms = nball_norms[batch_sense_indices]\n",
    "            target_directions = nball_embeddings[batch_sense_indices]\n",
    "\n",
    "            labels = torch.ones(directions.size(0), device=device)\n",
    "            loss_n_batch = loss_fn_n(norms, target_norms * 1e-5)\n",
    "            loss_d_batch = loss_fn_d(directions, target_directions, labels)\n",
    "            loss_n += loss_n_batch.item()\n",
    "            loss_d += loss_d_batch.item()\n",
    "\n",
    "            # Predict\n",
    "            output_embeddings = directions * norms.unsqueeze(-1)\n",
    "            for i in range(len(output_embeddings)):\n",
    "                size += 1\n",
    "                output_emb = output_embeddings[i]\n",
    "                candidate_indices = lemma_pair[batch_lemma_indices[i].item()]\n",
    "                candidate_norms = [nball_norms[idx] * 1e-5 for idx in candidate_indices]\n",
    "                candidate_directions = [nball_embeddings[idx] for idx in candidate_indices]\n",
    "                candidate_radii = [nball_radius[idx] for idx in candidate_indices]\n",
    "                predicted_index = predict_with_tree(tree, output_emb, candidate_indices, candidate_norms, candidate_directions, candidate_radii, nball_norms, nball_embeddings, nball_radius, index_to_label, label_to_index)\n",
    "                pred_indices[batch_idices[i].item()] = predicted_index\n",
    "                if predicted_index == batch_sense_indices[i].item():\n",
    "                    correct_predictions += 1\n",
    "                \n",
    "        total_batches = len(dataloader)\n",
    "        loss_n /= total_batches\n",
    "        loss_d /= total_batches\n",
    "        accuracy = correct_predictions / size\n",
    "\n",
    "    return loss_n, loss_d, accuracy, pred_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29a1442c-2731-4ba1-9616-7a98d4f185b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 20.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of norm:0.6490630046887831, average loss of dorection:0.002748901363123547\n",
      "Accurancy:83.52272727272727%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>word</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>lemma_idx</th>\n",
       "      <th>formatted_sense_id</th>\n",
       "      <th>sense_idx</th>\n",
       "      <th>sense_group</th>\n",
       "      <th>pred_sense_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>man</td>\n",
       "      <td>men</td>\n",
       "      <td>Whereas the eighteenth century had been a time...</td>\n",
       "      <td>131</td>\n",
       "      <td>homo.n.02</td>\n",
       "      <td>132</td>\n",
       "      <td>[132]</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horse</td>\n",
       "      <td>horse</td>\n",
       "      <td>One wrote : `` [ I am so hungry ] I could eat ...</td>\n",
       "      <td>255</td>\n",
       "      <td>horse.n.01</td>\n",
       "      <td>261</td>\n",
       "      <td>[261]</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wildcat</td>\n",
       "      <td>wildcat</td>\n",
       "      <td>She is well-educated and refined , all wildcat...</td>\n",
       "      <td>53</td>\n",
       "      <td>wildcat.n.03</td>\n",
       "      <td>54</td>\n",
       "      <td>[54]</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lion</td>\n",
       "      <td>Lions</td>\n",
       "      <td>To find out , we traveled throughout that part...</td>\n",
       "      <td>61</td>\n",
       "      <td>lion.n.01</td>\n",
       "      <td>62</td>\n",
       "      <td>[62]</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elephant</td>\n",
       "      <td>elephants</td>\n",
       "      <td>The Prince visited the hospital of Operation B...</td>\n",
       "      <td>103</td>\n",
       "      <td>elephant.n.01</td>\n",
       "      <td>104</td>\n",
       "      <td>[104]</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lemma       word                                      sentence_text  \\\n",
       "0       man        men  Whereas the eighteenth century had been a time...   \n",
       "1     horse      horse  One wrote : `` [ I am so hungry ] I could eat ...   \n",
       "2   wildcat    wildcat  She is well-educated and refined , all wildcat...   \n",
       "3      lion      Lions  To find out , we traveled throughout that part...   \n",
       "4  elephant  elephants  The Prince visited the hospital of Operation B...   \n",
       "\n",
       "   lemma_idx formatted_sense_id  sense_idx sense_group  pred_sense_idx  \n",
       "0        131          homo.n.02        132       [132]             132  \n",
       "1        255         horse.n.01        261       [261]             261  \n",
       "2         53       wildcat.n.03         54        [54]              54  \n",
       "3         61          lion.n.01         62        [62]              62  \n",
       "4        103      elephant.n.01        104       [104]             104  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_n, loss_d, accurancy, pred_indices = evaluation(model_n=model_norm, \\\n",
    "                                                     model_d=model_d,\\\n",
    "                                                     dataloader=dataloader_train)\n",
    "\n",
    "print(f\"Average loss of norm:{loss_n}, average loss of dorection:{loss_d}\")\n",
    "print(f\"Accurancy:{accurancy*100}%\")\n",
    "train_semcor['pred_sense_idx'] = train_semcor.index.map(pred_indices)\n",
    "display(train_semcor.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "567ec5b8-d493-4286-97cb-f66b0c658e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset:352\n",
      "Length of have only one element:330\n",
      "Length of mismatch:58\n",
      "Original accurancy:93.75%\n",
      "Filtered accurancy:-163.63636363636365%\n"
     ]
    }
   ],
   "source": [
    "set_length = len(train_semcor)\n",
    "\n",
    "count_single_element = (train_semcor['sense_group'].apply(lambda x: len(x) == 1)).sum()\n",
    "mismatch_count = (train_semcor['sense_idx'] != train_semcor['pred_sense_idx']).sum()\n",
    "count_multiple_element = set_length-count_single_element\n",
    "\n",
    "print(f\"Length of dataset:{set_length}\")\n",
    "print(f\"Length of have only one element:{count_single_element}\")\n",
    "print(f\"Length of mismatch:{mismatch_count}\")\n",
    "print(f\"Original accurancy:{count_single_element / set_length *100}%\")\n",
    "print(f\"Filtered accurancy:{(count_multiple_element-mismatch_count) /count_multiple_element  *100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b0655-51cf-4a07-8b84-f46c8416d2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dart4wsd",
   "language": "python",
   "name": "dart4wsd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
