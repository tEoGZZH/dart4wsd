{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0406b6f8-3f68-42ac-967b-26ecf22b31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from util import load_balls, preprocess_data\n",
    "from dataset import nballDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448cac41-e0c2-42ae-9e32-43d7ea8a0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_models = {\"BERT-Base\": [\"bert-base-uncased\", 768], #768, 12L, 12A\n",
    "               \"BERT-Large\": [\"bert-large-uncased\", 1024], #1024, 24L, 16A\n",
    "               \"BERT-Medium\": [\"google/bert_uncased_L-8_H-512_A-8\", 512], #512, 8L, 8A\n",
    "               \"BERT-Small\": [\"google/bert_uncased_L-4_H-256_A-4\", 256], #256, 4L, 4A\n",
    "               \"BERT-Mini\": [\"google/bert_uncased_L-4_H-128_A-2\", 128],#128, 4L, 2A\n",
    "               \"BERT-Tiny\": [\"google/bert_uncased_L-2_H-128_A-2\", 128]}#128, 2L, 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1081e6f-a1b0-4def-aa1f-a5d889ac31ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading balls....\n",
      "388 balls are loaded\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>word</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>formatted_sense_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>long</td>\n",
       "      <td>long</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>long.a.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be</td>\n",
       "      <td>been</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>be.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>review</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>review.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>objective</td>\n",
       "      <td>objectives</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>aim.n.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit</td>\n",
       "      <td>benefit</td>\n",
       "      <td>How long has it been since you reviewed the ob...</td>\n",
       "      <td>benefit.n.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lemma        word                                      sentence_text  \\\n",
       "0       long        long  How long has it been since you reviewed the ob...   \n",
       "1         be        been  How long has it been since you reviewed the ob...   \n",
       "2     review    reviewed  How long has it been since you reviewed the ob...   \n",
       "3  objective  objectives  How long has it been since you reviewed the ob...   \n",
       "4    benefit     benefit  How long has it been since you reviewed the ob...   \n",
       "\n",
       "  formatted_sense_id  \n",
       "0          long.a.01  \n",
       "1            be.v.01  \n",
       "2        review.v.01  \n",
       "3           aim.n.02  \n",
       "4       benefit.n.01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "semcor_training_xml_path = '../data/WSD_Evaluation_Framework/Training_Corpora/Semcor/semcor.data.xml'\n",
    "semcor_training_gk_path = '../data/WSD_Evaluation_Framework/Training_Corpora/Semcor/semcor.gold.key.txt'\n",
    "nball_mammal_file = '../data/sample_mammal/nball.txt'\n",
    "nball = load_balls(nball_mammal_file)\n",
    "training_set = preprocess_data(semcor_training_xml_path, semcor_training_gk_path)\n",
    "display(training_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed086779-f593-4e47-b4b1-72823232ac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "batch_size = 32\n",
    "model_url = bert_models[\"BERT-Small\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa78895-a234-4956-b956-a42b32027957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sentences...\n",
      "Tokenizing finished.\n",
      "Calculating word indices...\n",
      "Tokenizing finished.\n"
     ]
    }
   ],
   "source": [
    "dataset = nballDataset(training_set, nball, model_url, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91125d7f-a797-4a2b-891f-dc60e95f2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "240aa8f7-d20d-4bc0-9110-35ae5e3441e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class nballBertModelNorm(nn.Module):\n",
    "    def __init__(self, model_url, output_dim):\n",
    "        super(nballBertModelNorm, self).__init__()\n",
    "        self.model_url = model_url\n",
    "        self.bert = BertModel.from_pretrained(self.model_url)\n",
    "        self.projection = nn.Linear(self.bert.config.hidden_size, output_dim)\n",
    "        # Direct regression for norm\n",
    "        self.regressor = nn.Linear(output_dim, 1)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, word_index):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        word_embeddings = hidden_states[range(len(word_index)), word_index]\n",
    "        projected_output = self.projection(word_embeddings)\n",
    "        # norm = torch.norm(projected_output, p=2, dim=1) \n",
    "        norm = self.regressor(projected_output)\n",
    "        return norm\n",
    "\n",
    "\n",
    "class nballBertModelDirection(nn.Module):\n",
    "    def __init__(self, model_url, output_dim):\n",
    "        super(nballBertModelDirection, self).__init__()\n",
    "        self.model_url = model_url\n",
    "        self.bert = BertModel.from_pretrained(self.model_url)\n",
    "        self.projection = nn.Linear(self.bert.config.hidden_size, output_dim)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, word_index):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        word_embeddings = hidden_states[range(len(word_index)), word_index]\n",
    "        projected_output = self.projection(word_embeddings)\n",
    "        return projected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9c12e8a-c83e-45f7-995a-95fc20631b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config for training norm\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "def log_cosh_loss(norm_u, norm_v):\n",
    "    return torch.log(torch.cosh(norm_u - norm_v)).mean()\n",
    "\n",
    "output_dim = 160\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = nballBertModelNorm(model_url, output_dim).to(device)\n",
    "loss_fn = log_cosh_loss\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.parameters()}\n",
    "], lr=2e-4)\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5ba3056-3bc7-48e6-8556-8a42cc65549d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|███████████████████████████████████████████████████████████| 11/11 [00:01<00:00,  5.84it/s, loss=5.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 5.846156120300293, Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.08it/s, loss=2.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Avg Loss: 4.522917248985984, Improvement: 1.3232388713143088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.15it/s, loss=2.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Avg Loss: 3.78069747578014, Improvement: 0.7422197732058439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.27it/s, loss=2.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Avg Loss: 2.9006378759037363, Improvement: 0.8800595998764038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.04it/s, loss=2.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Avg Loss: 2.109628135507757, Improvement: 0.7910097403959795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|███████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.15it/s, loss=0.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Avg Loss: 1.5353513360023499, Improvement: 0.5742767995054071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.60it/s, loss=0.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Avg Loss: 1.0814559676430442, Improvement: 0.45389536835930566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.93it/s, loss=1.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Avg Loss: 0.783914177255197, Improvement: 0.2975417903878472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|█████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.60it/s, loss=0.841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Avg Loss: 0.8396749374541369, Improvement: -0.05576076019893993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.48it/s, loss=0.593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Avg Loss: 0.6135393435304816, Improvement: 0.22613559392365543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|█████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.60it/s, loss=0.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Avg Loss: 0.5545219315046613, Improvement: 0.05901741202582012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.42it/s, loss=0.463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Avg Loss: 0.47430757636373694, Improvement: 0.08021435514092445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|█████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.33it/s, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Avg Loss: 0.4394462362609126, Improvement: 0.034861340102824295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.52it/s, loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Avg Loss: 0.3773611770434813, Improvement: 0.06208505921743133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.87it/s, loss=0.313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Avg Loss: 0.32993696960197255, Improvement: 0.04742420744150877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.35it/s, loss=0.0335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Avg Loss: 0.3027864149348302, Improvement: 0.027150554667142304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.64it/s, loss=0.442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Avg Loss: 0.2521745894442905, Improvement: 0.050611825490539726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.18it/s, loss=0.021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Avg Loss: 0.2151418968357823, Improvement: 0.037032692608508194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.10it/s, loss=0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Avg Loss: 0.16217678594826299, Improvement: 0.05296511088751934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.07it/s, loss=0.0102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Avg Loss: 0.12320002490146593, Improvement: 0.03897676104679704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.07it/s, loss=0.0584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Avg Loss: 0.08655363880097866, Improvement: 0.036646386100487274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.94it/s, loss=0.0611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Avg Loss: 0.09811161678623069, Improvement: -0.011557977985252033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.27it/s, loss=0.0559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Avg Loss: 0.05993401072919369, Improvement: 0.03817760605703701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.13it/s, loss=0.0618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Avg Loss: 0.05307962593029846, Improvement: 0.006854384798895229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.90it/s, loss=0.0345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Avg Loss: 0.03619324483654716, Improvement: 0.0168863810937513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.02it/s, loss=0.0133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Avg Loss: 0.050331651233136654, Improvement: -0.014138406396589497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.04it/s, loss=0.0632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Avg Loss: 0.038218934258276764, Improvement: 0.012112716974859888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.58it/s, loss=0.0351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Avg Loss: 0.03515535169704394, Improvement: 0.0030635825612328267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.50it/s, loss=0.0456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Avg Loss: 0.03436837751757015, Improvement: 0.0007869741794737903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.49it/s, loss=0.0378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Avg Loss: 0.03459800034761429, Improvement: -0.0002296228300441395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.62it/s, loss=0.038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Avg Loss: 0.037153054706074974, Improvement: -0.0025550543584606862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.40it/s, loss=0.0317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Avg Loss: 0.05160939998247407, Improvement: -0.014456345276399092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.91it/s, loss=0.0251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Avg Loss: 0.03356578658250245, Improvement: 0.018043613399971615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.20it/s, loss=0.0217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Avg Loss: 0.025271593931723724, Improvement: 0.008294192650778727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.59it/s, loss=0.0227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Avg Loss: 0.017236900558187204, Improvement: 0.008034693373536522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.24it/s, loss=0.0108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Avg Loss: 0.0105466702952981, Improvement: 0.006690230262889104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.45it/s, loss=0.0115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Avg Loss: 0.00957026065919887, Improvement: 0.0009764096360992302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.89it/s, loss=0.00472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Avg Loss: 0.008427517700263044, Improvement: 0.0011427429589358244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.93it/s, loss=0.00557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Avg Loss: 0.008134554754095998, Improvement: 0.00029296294616704637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.19it/s, loss=0.0092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Avg Loss: 0.01032001735769551, Improvement: -0.00218546260359951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.07it/s, loss=0.00343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Avg Loss: 0.00448079865468158, Improvement: 0.005839218703013929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.04it/s, loss=0.00255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Avg Loss: 0.00434125994797796, Improvement: 0.0001395387067036195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.43it/s, loss=0.00395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Avg Loss: 0.005709279116920449, Improvement: -0.0013680191689424894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.39it/s, loss=0.0029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Avg Loss: 0.005141135093502023, Improvement: 0.0005681440234184265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.94it/s, loss=0.00527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Avg Loss: 0.004047363610218533, Improvement: 0.00109377148328349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.39it/s, loss=0.0146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Avg Loss: 0.01108101829463108, Improvement: -0.007033654684412547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.17it/s, loss=0.00277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Avg Loss: 0.013457082063806329, Improvement: -0.0023760637691752477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.86it/s, loss=0.0219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Avg Loss: 0.011388894424519756, Improvement: 0.0020681876392865724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.11it/s, loss=0.00612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Avg Loss: 0.011653495761989192, Improvement: -0.0002646013374694369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.98it/s, loss=0.00753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Avg Loss: 0.009047871646047994, Improvement: 0.0026056241159411993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.49it/s, loss=0.00324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Avg Loss: 0.0034466858170079913, Improvement: 0.005601185829040001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.38it/s, loss=0.00177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Avg Loss: 0.0022433789827945557, Improvement: 0.0012033068342134356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.87it/s, loss=0.00157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Avg Loss: 0.0015118756405585868, Improvement: 0.0007315033422359688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.61it/s, loss=0.000723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Avg Loss: 0.0011240551406940954, Improvement: 0.0003878204998644915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.20it/s, loss=0.000707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Avg Loss: 0.0009107958493669602, Improvement: 0.00021325929132713512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.58it/s, loss=0.000681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Avg Loss: 0.0007419751888268034, Improvement: 0.00016882066054015675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.78it/s, loss=0.000609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Avg Loss: 0.0006368549392473968, Improvement: 0.0001051202495794066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.97it/s, loss=0.000619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Avg Loss: 0.0005507201157425615, Improvement: 8.613482350483537e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.03it/s, loss=0.000514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Avg Loss: 0.0004926371753258122, Improvement: 5.808294041674923e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.01it/s, loss=0.000346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Avg Loss: 0.00044370099203661084, Improvement: 4.8936183289201423e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.26it/s, loss=0.000268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Avg Loss: 0.00039159217769999736, Improvement: 5.21088143366135e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.10it/s, loss=0.000391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Avg Loss: 0.00035472120957406747, Improvement: 3.6870968125929885e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.16it/s, loss=0.000302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Avg Loss: 0.0003288795679426667, Improvement: 2.584164163140072e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.06it/s, loss=0.000269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, Avg Loss: 0.0002826128752944483, Improvement: 4.626669264821844e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.54it/s, loss=0.000287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, Avg Loss: 0.0002588067582109943, Improvement: 2.3806117083453998e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.64it/s, loss=0.000241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, Avg Loss: 0.00024114775905300948, Improvement: 1.7658999157984827e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.47it/s, loss=0.000263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Avg Loss: 0.00023165998176078904, Improvement: 9.48777729222043e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.10it/s, loss=0.00013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Avg Loss: 0.00020215414538556203, Improvement: 2.950583637522703e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.02it/s, loss=0.000119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, Avg Loss: 0.0001859645218990574, Improvement: 1.6189623486504637e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.24it/s, loss=0.000157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Avg Loss: 0.00017274602578254417, Improvement: 1.3218496116513217e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.17it/s, loss=0.000114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, Avg Loss: 0.00016735024903689256, Improvement: 5.395776745651594e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.13it/s, loss=0.000188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, Avg Loss: 0.00015256444550521502, Improvement: 1.4785803531677546e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.07it/s, loss=0.000193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73, Avg Loss: 0.00014494737313891, Improvement: 7.617072366305035e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.15it/s, loss=0.000106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74, Avg Loss: 0.0001519603372964246, Improvement: -7.012964157514613e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.20it/s, loss=0.00015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, Avg Loss: 0.00014060843651267615, Improvement: 1.135190078374845e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.37it/s, loss=0.000116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, Avg Loss: 0.00012388807623541322, Improvement: 1.672036027726294e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.08it/s, loss=0.000136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77, Avg Loss: 0.00011295161675661802, Improvement: 1.093645947879519e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.48it/s, loss=0.000152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, Avg Loss: 0.00010241205150536685, Improvement: 1.0539565251251174e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.49it/s, loss=0.000103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79, Avg Loss: 0.00010130138848167421, Improvement: 1.1106630236926405e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.46it/s, loss=0.000139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Avg Loss: 9.209896564822306e-05, Improvement: 9.202422833451154e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.56it/s, loss=6.52e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, Avg Loss: 8.671861955504441e-05, Improvement: 5.380346093178642e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.36it/s, loss=0.000105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, Avg Loss: 8.321542058679783e-05, Improvement: 3.503198968246579e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.70it/s, loss=6.06e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83, Avg Loss: 7.97110948372971e-05, Improvement: 3.5043257495007394e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.44it/s, loss=6.61e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84, Avg Loss: 7.215462987501682e-05, Improvement: 7.556464962280271e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.68it/s, loss=6.75e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85, Avg Loss: 7.314487513874404e-05, Improvement: -9.902452637272126e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.52it/s, loss=7.34e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, Avg Loss: 6.923606303065422e-05, Improvement: 3.908812108089808e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.50it/s, loss=3.73e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, Avg Loss: 6.541811407342638e-05, Improvement: 3.8179489572278476e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.46it/s, loss=6.69e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88, Avg Loss: 5.98189071752131e-05, Improvement: 5.5992068982132794e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.59it/s, loss=8.73e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, Avg Loss: 5.691007225488482e-05, Improvement: 2.90883492032828e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.48it/s, loss=4.02e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Avg Loss: 5.679300176614726e-05, Improvement: 1.1707048873755742e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.39it/s, loss=8.08e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91, Avg Loss: 5.386127073010853e-05, Improvement: 2.9317310360387307e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.59it/s, loss=7.5e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92, Avg Loss: 5.4815287843336016e-05, Improvement: -9.54017113227482e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.50it/s, loss=4.93e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93, Avg Loss: 4.8931710559620775e-05, Improvement: 5.883577283715237e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.90it/s, loss=5.53e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94, Avg Loss: 4.8297861047269016e-05, Improvement: 6.338495123517615e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.48it/s, loss=4.2e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, Avg Loss: 4.532271701794922e-05, Improvement: 2.9751440293197944e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.59it/s, loss=4.46e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96, Avg Loss: 4.704666439052248e-05, Improvement: -1.7239473725732586e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: 100%|█████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.35it/s, loss=4e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97, Avg Loss: 4.371667670387648e-05, Improvement: 3.3299876866460014e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.54it/s, loss=5.22e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98, Avg Loss: 4.1171626435243525e-05, Improvement: 2.5450502686329526e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100: 100%|██████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.53it/s, loss=4.35e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99, Avg Loss: 3.8986899116108276e-05, Improvement: 2.184727319135246e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|█████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.49it/s, loss=4.71e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Avg Loss: 3.68146700731648e-05, Improvement: 2.1722290429434823e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "last_loss = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=True, position=0)\n",
    "    for batch in progress_bar:\n",
    "        # Unpack batch and send to device\n",
    "        batch_input_ids, batch_attention_masks, batch_word_indices, batch_nball, batch_norm\\\n",
    "        , batch_sense_indices = [b.to(device) for b in batch]\n",
    "        b_norm = batch_norm.squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output_norm = model(input_ids=batch_input_ids, attention_mask=batch_attention_masks, \\\n",
    "                            word_index=batch_word_indices).squeeze()\n",
    "\n",
    "        loss = loss_fn(output_norm, batch_norm * 1e-5)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Logging average metrics per epoch\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    improvement = (last_loss - total_loss) / len(dataloader) if last_loss != 0 else 0\n",
    "    print(f'Epoch {epoch + 1}, Avg Loss: {avg_loss}, Improvement: {improvement}')\n",
    "    last_loss = total_loss\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "088e1050-9212-438e-8530-4228335e454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "output_dim = 160\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_d = nballBertModelDirection(model_url, output_dim).to(device)\n",
    "loss_fn_d = nn.CosineEmbeddingLoss()\n",
    "optimizer_d = optim.Adam(model_d.parameters(), lr=2e-5)\n",
    "num_epochs = 10\n",
    "last_loss = 0\n",
    "scheduler_d = StepLR(optimizer_d, step_size=50, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c47e1e3-a3f9-43ff-91cf-a0d65930155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.58it/s, loss=0.609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 0.7251736304976724, Improvement: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.91it/s, loss=0.372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Avg Loss: 0.47107029232111847, Improvement: 0.2541033381765539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.39it/s, loss=0.234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Avg Loss: 0.29637267643755133, Improvement: 0.1746976158835671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.99it/s, loss=0.146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Avg Loss: 0.18235064230181955, Improvement: 0.11402203413573178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|█████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.99it/s, loss=0.0887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Avg Loss: 0.1104935800487345, Improvement: 0.07185706225308505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|█████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.98it/s, loss=0.0524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Avg Loss: 0.06592883711511438, Improvement: 0.04456474293362011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|█████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.07it/s, loss=0.0295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Avg Loss: 0.0387784769250588, Improvement: 0.027150360190055588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|█████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.20it/s, loss=0.0203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Avg Loss: 0.023032866926355797, Improvement: 0.015745609998703003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 13.11it/s, loss=0.011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Avg Loss: 0.014601276340809736, Improvement: 0.00843159058554606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|███████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.10it/s, loss=0.00922]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Avg Loss: 0.01011386208913543, Improvement: 0.004487414251674305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=True, position=0)\n",
    "    for batch in progress_bar:\n",
    "        batch_input_ids, batch_attention_masks, batch_word_indices, batch_sense_indices,\\\n",
    "        batch_nball, batch_norm = [b.to(device) for b in batch]\n",
    "\n",
    "        optimizer_d.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        word_embeddings = model_d(input_ids=batch_input_ids, attention_mask=batch_attention_masks, \\\n",
    "                                  word_index=batch_word_indices).squeeze()\n",
    "\n",
    "        # Labels tensor indicating that embeddings should be similar\n",
    "        labels = torch.ones(word_embeddings.size(0), device=device)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn_d(word_embeddings, batch_nball, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Logging average metrics per epoch\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    improvement = (last_loss - total_loss) / len(dataloader) if last_loss != 0 else 0\n",
    "    print(f'Epoch {epoch + 1}, Avg Loss: {avg_loss}, Improvement: {improvement}')\n",
    "    last_loss = total_loss\n",
    "\n",
    "    scheduler_d.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4191f9ed-9bb2-4d42-9406-d172caaed203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading balls....\n",
      "388 balls are loaded\n",
      "\n",
      "Tokenizing sentences...\n",
      "Tokenizing finished.\n",
      "Calculating word indices...\n",
      "Tokenizing finished.\n"
     ]
    }
   ],
   "source": [
    "# Config for dataset\n",
    "data_path_eval = {\"xml\":'../data/WSD_Evaluation_Framework/Evaluation_Datasets/ALL/ALL.data.xml',\n",
    "                  \"gold_key\":'../data/WSD_Evaluation_Framework/Evaluation_Datasets/ALL/ALL.gold.key.txt',\n",
    "                  \"nball\":'../data/sample_mammal/nball.txt'}\n",
    "dataset_eval = dataset = nballDataset(data_path_eval, model_name, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c534c0e3-c9bc-4d0e-b6c9-dea3ca8dfc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 162.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "Average Evaluation Loss: 4.455964071067601e-05\n",
      "Accuracy: 60.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Switch model to evaluation mode\n",
    "# eval_dataloader = dataloader\n",
    "eval_dataloader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "model.eval()\n",
    "\n",
    "# Store evaluation results\n",
    "eval_loss = 0\n",
    "accuracy = 0  # Placeholder for accuracy calculation\n",
    "total_samples = 0\n",
    "correct_predictions = 0\n",
    "loss_fn2 = nn.SmoothL1Loss(reduction=\"mean\", beta=1e-3)\n",
    "# Disable gradient computation for evaluation to save memory and computations\n",
    "with torch.no_grad():\n",
    "    all_output_norms = []\n",
    "    all_true_norms = []\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluation\", leave=True, position=0):\n",
    "         # Unpack batch and send to device\n",
    "        batch_input_ids, batch_attention_masks, batch_word_indices, batch_sense_indices,\\\n",
    "        batch_nball, batch_norm = [b.to(device) for b in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output_norm = model(input_ids=batch_input_ids, attention_mask=batch_attention_masks, \\\n",
    "                            word_index=batch_word_indices).squeeze()\n",
    "\n",
    "        print(output_norm.shape)\n",
    "        loss = loss_fn2(output_norm, batch_norm * 1e-5)\n",
    "        # Retrieve the corresponding sense embeddings and radius\n",
    "        eval_loss += loss.item()\n",
    "        \n",
    "        # print(output_norm.shape)\n",
    "        # print(batch_norm.shape)\n",
    "        all_output_norms.append(output_norm)\n",
    "        all_true_norms.append(batch_norm * 1e-5)\n",
    "\n",
    "\n",
    "    \n",
    "    # Concatenate all norms\n",
    "    all_output_norms = torch.cat(all_output_norms)\n",
    "    all_true_norms = torch.cat(all_true_norms)\n",
    "    all_difference = torch.abs(all_true_norms - all_output_norms)\n",
    "        \n",
    "    # Calculate predictions\n",
    "    ture_idxs = []\n",
    "    pred_idxs = []\n",
    "    for i in range(all_true_norms.size(0)):\n",
    "        pred_idx = (torch.abs(all_output_norms - all_true_norms[i])).argmin()\n",
    "        ture_idxs.append(i)\n",
    "        pred_idxs.append(pred_idx)\n",
    "        if pred_idx == i:\n",
    "            correct_predictions += 1\n",
    "        total_samples += 1\n",
    "        \n",
    "avg_loss = total_loss / len(dataloader)\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "\n",
    "# # Compute average loss and accuracy\n",
    "eval_loss /= len(eval_dataloader)\n",
    "accuracy /= len(eval_dataloader)\n",
    "\n",
    "print(f\"Average Evaluation Loss: {avg_loss}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bda39da-784c-4701-8a1e-d6156c03b941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([1.1907e-03, 1.8126e-03, 2.7509e-03, 3.0651e-03, 3.4022e-03, 4.2477e-03,\n",
       "        5.9280e-03, 5.9338e-03, 6.4397e-03, 6.7889e-03, 6.9675e-03, 7.5798e-03,\n",
       "        7.5798e-03, 7.6894e-03, 8.4160e-03, 8.5786e-03, 1.0227e-02, 1.0549e-02,\n",
       "        1.1972e-02, 1.2384e-02, 1.2879e-02, 1.2973e-02, 1.3520e-02, 1.5911e-02,\n",
       "        1.7061e-02, 1.7208e-02, 1.7367e-02, 1.7483e-02, 1.8055e-02, 1.8095e-02,\n",
       "        1.8338e-02, 1.8438e-02, 1.9443e-02, 1.9598e-02, 1.9850e-02, 2.0161e-02,\n",
       "        2.0207e-02, 2.0338e-02, 2.1139e-02, 2.2595e-02, 2.2705e-02, 2.2745e-02,\n",
       "        2.2933e-02, 2.3220e-02, 2.3399e-02, 2.3670e-02, 2.4330e-02, 2.4610e-02,\n",
       "        2.4878e-02, 2.5316e-02, 2.5760e-02, 2.6990e-02, 2.7020e-02, 2.7074e-02,\n",
       "        2.7360e-02, 2.7923e-02, 2.7992e-02, 2.8166e-02, 2.8888e-02, 2.9163e-02,\n",
       "        2.9317e-02, 3.0143e-02, 3.0733e-02, 3.1081e-02, 3.1653e-02, 3.2272e-02,\n",
       "        3.2480e-02, 3.2574e-02, 3.4225e-02, 3.4700e-02, 3.5622e-02, 3.5851e-02,\n",
       "        3.6342e-02, 3.6376e-02, 3.7014e-02, 3.7132e-02, 3.7646e-02, 3.7695e-02,\n",
       "        3.7854e-02, 3.8347e-02, 3.9475e-02, 4.0462e-02, 4.0466e-02, 4.0599e-02,\n",
       "        4.1327e-02, 4.1329e-02, 4.5311e-02, 4.5659e-02, 4.5800e-02, 4.8466e-02,\n",
       "        4.8717e-02, 4.8998e-02, 4.9110e-02, 4.9701e-02, 5.0041e-02, 5.0491e-02,\n",
       "        5.0491e-02, 5.1567e-02, 5.1939e-02, 5.2198e-02, 5.2390e-02, 5.2390e-02,\n",
       "        5.2488e-02, 5.2868e-02, 5.2959e-02, 5.4966e-02, 5.5303e-02, 5.6661e-02,\n",
       "        5.7534e-02, 5.7754e-02, 5.8297e-02, 5.8763e-02, 5.8826e-02, 5.9146e-02,\n",
       "        5.9539e-02, 6.0355e-02, 6.0421e-02, 6.0509e-02, 6.0526e-02, 6.1697e-02,\n",
       "        6.1747e-02, 6.2216e-02, 6.3196e-02, 6.3349e-02, 6.6730e-02, 6.7545e-02,\n",
       "        6.7594e-02, 6.7676e-02, 6.7676e-02, 6.7722e-02, 6.8581e-02, 6.8605e-02,\n",
       "        7.0130e-02, 7.1213e-02, 7.2121e-02, 7.2723e-02, 7.4240e-02, 7.4574e-02,\n",
       "        7.6226e-02, 7.7123e-02, 7.7534e-02, 7.8685e-02, 7.8851e-02, 7.9550e-02,\n",
       "        8.0863e-02, 8.1936e-02, 8.2544e-02, 8.2560e-02, 8.2874e-02, 8.3309e-02,\n",
       "        8.4251e-02, 8.5260e-02, 8.5382e-02, 8.6246e-02, 8.6352e-02, 8.8973e-02,\n",
       "        8.9071e-02, 8.9464e-02, 8.9514e-02, 8.9689e-02, 9.0155e-02, 9.3112e-02,\n",
       "        9.3112e-02, 9.3144e-02, 9.5009e-02, 9.5148e-02, 9.5228e-02, 9.5322e-02,\n",
       "        9.5352e-02, 9.5476e-02, 9.5512e-02, 9.6015e-02, 9.6405e-02, 9.6912e-02,\n",
       "        9.7013e-02, 9.7865e-02, 9.7957e-02, 9.8078e-02, 9.9523e-02, 1.0257e-01,\n",
       "        1.0268e-01, 1.0273e-01, 1.0287e-01, 1.0461e-01, 1.0496e-01, 1.0542e-01,\n",
       "        1.0572e-01, 1.0845e-01, 1.0922e-01, 1.0975e-01, 1.1025e-01, 1.1103e-01,\n",
       "        1.1151e-01, 1.1168e-01, 1.1180e-01, 1.1256e-01, 1.1262e-01, 1.1357e-01,\n",
       "        1.1384e-01, 1.1447e-01, 1.1469e-01, 1.1532e-01, 1.1532e-01, 1.1534e-01,\n",
       "        1.1534e-01, 1.1538e-01, 1.1604e-01, 1.1616e-01, 1.1744e-01, 1.1812e-01,\n",
       "        1.1959e-01, 1.1989e-01, 1.2011e-01, 1.2171e-01, 1.2242e-01, 1.2276e-01,\n",
       "        1.2276e-01, 1.2342e-01, 1.2442e-01, 1.2500e-01, 1.2545e-01, 1.2556e-01,\n",
       "        1.2601e-01, 1.2713e-01, 1.2752e-01, 1.2974e-01, 1.3102e-01, 1.3147e-01,\n",
       "        1.3165e-01, 1.3165e-01, 1.3225e-01, 1.3228e-01, 1.3295e-01, 1.3384e-01,\n",
       "        1.3510e-01, 1.3599e-01, 1.3684e-01, 1.3722e-01, 1.3746e-01, 1.3855e-01,\n",
       "        1.4008e-01, 1.4052e-01, 1.4080e-01, 1.4109e-01, 1.4142e-01, 1.4185e-01,\n",
       "        1.4441e-01, 1.4619e-01, 1.4702e-01, 1.4703e-01, 1.4725e-01, 1.4753e-01,\n",
       "        1.5036e-01, 1.5077e-01, 1.5104e-01, 1.5163e-01, 1.5375e-01, 1.5404e-01,\n",
       "        1.5480e-01, 1.5488e-01, 1.5775e-01, 1.5837e-01, 1.5887e-01, 1.6022e-01,\n",
       "        1.6049e-01, 1.6127e-01, 1.6177e-01, 1.6564e-01, 1.6651e-01, 1.6783e-01,\n",
       "        1.7070e-01, 1.7087e-01, 1.7229e-01, 1.7275e-01, 1.7309e-01, 1.7383e-01,\n",
       "        1.7418e-01, 1.7992e-01, 1.8295e-01, 1.8381e-01, 1.8608e-01, 1.9238e-01,\n",
       "        1.9332e-01, 1.9680e-01, 2.0711e-01, 2.0776e-01, 2.0957e-01, 2.1051e-01,\n",
       "        2.1170e-01, 2.1321e-01, 2.1650e-01, 2.1689e-01, 2.1839e-01, 2.2045e-01,\n",
       "        2.2138e-01, 2.2511e-01, 2.2948e-01, 2.3166e-01, 2.3407e-01, 2.3477e-01,\n",
       "        2.3480e-01, 2.3589e-01, 2.3589e-01, 2.4425e-01, 2.4485e-01, 2.4806e-01,\n",
       "        2.5308e-01, 2.5316e-01, 2.5469e-01, 2.6473e-01, 2.6695e-01, 2.7081e-01,\n",
       "        2.7218e-01, 2.7218e-01, 2.7421e-01, 2.7743e-01, 2.8618e-01, 2.8781e-01,\n",
       "        3.0807e-01, 3.1114e-01, 3.1154e-01, 3.3133e-01, 3.4695e-01, 3.4767e-01,\n",
       "        3.4791e-01, 3.4841e-01, 3.5116e-01, 3.5872e-01, 3.6125e-01, 3.6169e-01,\n",
       "        3.6856e-01, 3.7602e-01, 3.9569e-01, 4.0069e-01, 4.1426e-01, 4.2110e-01,\n",
       "        4.4373e-01, 4.5365e-01, 4.7874e-01, 4.9638e-01, 6.7967e-01, 1.0646e+01,\n",
       "        1.0649e+01, 1.0649e+01, 1.0651e+01, 1.0657e+01, 1.0660e+01, 1.0665e+01,\n",
       "        1.0669e+01, 1.0676e+01, 1.0692e+01, 1.0696e+01], device='cuda:0'),\n",
       "indices=tensor([ 23, 274,  19, 116, 188, 180, 208,  30,  35,  10, 124, 335, 265,  90,\n",
       "         46, 192,  86,  74, 345, 216,  15, 129, 122, 242,  59, 304, 347, 106,\n",
       "        223, 224, 110,  61, 311, 328,  80, 214,   2, 163,  64, 134, 156, 276,\n",
       "        314, 227, 112, 111, 266, 167,  83,  89, 184, 300, 316, 263,  20, 160,\n",
       "        225, 181, 295, 220, 132, 126, 108, 334, 140, 243, 349, 256, 306,  41,\n",
       "        320, 308, 118,  97, 102, 119, 315, 291,  36, 252, 173, 247, 199, 294,\n",
       "        107, 196, 120, 212, 284, 197,  37, 332, 313, 241, 217, 270, 245, 221,\n",
       "        228,  16,  13, 272, 233, 213,  47,  79,  32, 333, 262,  54, 127, 289,\n",
       "        230,  58,  84, 312, 157, 240,   4, 109, 150, 153, 321, 165, 135, 298,\n",
       "        250,   5, 183, 264, 348,  14,  68, 114, 319,  96,  67, 219, 260,  69,\n",
       "        310, 329, 275, 339, 281, 307,  27,  75, 178, 288,  71, 323,  50, 338,\n",
       "          8, 215, 149, 290, 293,  29,  63,  44, 282, 297, 261, 202, 125, 257,\n",
       "        286, 255, 144, 248, 238, 330, 278,  24,  42, 100,  88, 159, 177, 283,\n",
       "        142, 154, 171,  43, 239, 324, 305, 136, 231, 152, 236, 131, 198,  77,\n",
       "        337, 342, 147,  53,   7,  34, 200,  66, 258,   1,  28,  95,  98,  92,\n",
       "        269, 287, 222,  25,  82,  45,  21, 133, 271, 244, 174,  17, 204, 218,\n",
       "        340, 226, 175,  85, 280, 249,  39, 254, 331, 206, 318, 169,  22,  11,\n",
       "          6,   0, 203,  93, 128, 341,  31, 317, 251, 301, 179, 232, 186, 164,\n",
       "        267, 185, 170,  51, 350,  73, 229, 234, 336,  65, 309,  55, 189, 103,\n",
       "        104, 146, 113, 158,  56,  76,  33,  78, 322, 191, 302, 279,  72, 121,\n",
       "        273, 207, 259, 343,  60, 141,  48,   9, 303, 201,  57, 155, 166,  62,\n",
       "        253, 190, 168,  18, 151, 268, 138, 351, 139, 299, 194, 346, 344,  91,\n",
       "        161,  87,  12, 187, 193, 143,  52, 115,  38,  40, 296, 235, 327, 148,\n",
       "        172, 246, 117, 285,  94, 123, 292, 101, 325,   3, 209, 210, 326,  70,\n",
       "         81, 211, 195, 176, 162, 277,  49, 105, 182,  26, 130, 237, 205, 145,\n",
       "        137,  99], device='cuda:0'))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_difference.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e14c5b71-c9e4-4e0f-b841-10e35ca2044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = []\n",
    "\n",
    "for data in dataloader:\n",
    "    _, _, _, _, _, norm = data\n",
    "    norm_cpu = norm.cpu()\n",
    "    for n in norm:       \n",
    "        norms.append(n.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7436369c-1a85-4244-bffc-351e91fca676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:4\n",
      "Ture:0.41670626401901245, output:1.2976804971694946, predict:0.23294714093208313\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "diff_pers = []\n",
    "diffs = []\n",
    "output_norms = all_output_norms.cpu()\n",
    "ture_norms = all_true_norms.cpu()\n",
    "correct = 0\n",
    "\n",
    "outliers = []\n",
    "for i in range(len(ture_norms)):\n",
    "    ture_norm = ture_norms[i]\n",
    "    output_norm = output_norms[i]\n",
    "    pred_norm = all_true_norms[pred_idxs[i]]\n",
    "    if torch.abs(pred_norm - ture_norm) < 1e-5:\n",
    "        correct+=1\n",
    "    else:\n",
    "        outliers.append([ture_norm, output_norm, pred_norm])\n",
    "    # print(f\"Ture:{ture_norm}, output:{output_norm}, predict:{pred_norm}\")\n",
    "print(f\"correct:{correct}\")\n",
    "\n",
    "\n",
    "for o in outliers:\n",
    "    print(f\"Ture:{o[0]}, output:{o[1]}, predict:{o[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9f85340f-60be-4b97-8e89-2836c6dddebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n",
      "29 left (8.238636363636363%), with filter=0\n",
      "29 left (8.238636363636363%), with filter=0.01\n",
      "67 left (19.03409090909091%), with filter=0.1\n",
      "173 left (49.14772727272727%), with filter=1.0\n",
      "271 left (76.98863636363636%), with filter=10.0\n",
      "330 left (93.75%), with filter=100.0\n",
      "352 left (100.0%), with filter=1000.0\n",
      "352 left (100.0%), with filter=10000.0\n",
      "352 left (100.0%), with filter=100000.0\n",
      "352 left (100.0%), with filter=1000000.0\n",
      "352 left (100.0%), with filter=10000000.0\n"
     ]
    }
   ],
   "source": [
    "diff_pers.sort()\n",
    "l = len(diff_pers)\n",
    "print(l)\n",
    "\n",
    "f = [d for d in diff_pers if d == 0]\n",
    "    print(f\"{len(f)} left ({len(f)/l*100}%), with filter={filter}\")\n",
    "\n",
    "filter = 0.01\n",
    "for i in range(10):\n",
    "    f = [d for d in diff_pers if d < filter]\n",
    "    print(f\"{len(f)} left ({len(f)/l*100}%), with filter={filter}\")\n",
    "    filter *= 10\n",
    "    \n",
    "# a = [d for d in diff_pers if d < 0.05]\n",
    "# a = [d for d in diff_pers if d < 0.5]\n",
    "# print(len(diff_pers), len(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "21b4b7bc-b01a-4240-9091-77eba4c2987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.63685774699818\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(diffs)*1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0e35dfab-5766-4ade-adb0-de4700e6bcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.boxplot(norms, vert=False)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Box Plot of Data')\n",
    "plt.xlabel('Value')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4fcbe6f-5853-4c89-932a-e2dcc4caabb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10509.4345703125,\n",
       " 10509.4345703125,\n",
       " 11779.2177734375,\n",
       " 11779.2177734375,\n",
       " 11779.2177734375,\n",
       " 11779.2177734375,\n",
       " 11779.2177734375,\n",
       " 11779.2177734375,\n",
       " 11779.2177734375,\n",
       " 11779.2177734375,\n",
       " 11779.2177734375,\n",
       " 11779.2177734375,\n",
       " 11779.2177734375,\n",
       " 11779.2177734375,\n",
       " 12028.517578125,\n",
       " 12028.517578125,\n",
       " 12028.517578125,\n",
       " 13139.8212890625,\n",
       " 13830.6201171875,\n",
       " 13830.6201171875,\n",
       " 15364.796875,\n",
       " 15370.0712890625,\n",
       " 15370.0712890625,\n",
       " 16237.2568359375,\n",
       " 16237.2568359375,\n",
       " 16237.2568359375,\n",
       " 16237.2568359375,\n",
       " 16237.2568359375,\n",
       " 16237.2568359375,\n",
       " 16237.2568359375,\n",
       " 16237.2568359375,\n",
       " 23294.71484375,\n",
       " 23294.71484375,\n",
       " 23294.71484375,\n",
       " 23294.71484375,\n",
       " 23294.71484375,\n",
       " 23294.71484375,\n",
       " 23294.71484375,\n",
       " 23294.71484375,\n",
       " 23294.71484375,\n",
       " 23294.71484375,\n",
       " 23294.71484375,\n",
       " 23294.71484375,\n",
       " 23294.71484375,\n",
       " 23294.71484375,\n",
       " 24828.53125,\n",
       " 24828.53125,\n",
       " 24828.53125,\n",
       " 24828.53125,\n",
       " 38025.72265625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 41684.5390625,\n",
       " 56572.61328125,\n",
       " 56572.61328125,\n",
       " 56572.61328125,\n",
       " 56572.61328125,\n",
       " 56572.61328125,\n",
       " 56572.61328125,\n",
       " 56572.61328125,\n",
       " 56572.61328125,\n",
       " 105432.5234375,\n",
       " 124115.46875,\n",
       " 135674.984375,\n",
       " 135674.984375,\n",
       " 135674.984375,\n",
       " 166421.703125,\n",
       " 166421.703125,\n",
       " 174416.46875,\n",
       " 188750.328125,\n",
       " 193727.21875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 194066.046875,\n",
       " 322963.59375,\n",
       " 322963.59375,\n",
       " 322963.59375,\n",
       " 347647.96875,\n",
       " 347647.96875,\n",
       " 347647.96875,\n",
       " 347647.96875,\n",
       " 347647.96875,\n",
       " 347647.96875,\n",
       " 377378.5,\n",
       " 377378.5,\n",
       " 413585.0,\n",
       " 413585.0,\n",
       " 413585.0,\n",
       " 413585.0,\n",
       " 413585.0,\n",
       " 413585.0,\n",
       " 413585.0,\n",
       " 413585.0,\n",
       " 413585.0,\n",
       " 413585.0,\n",
       " 442711.75,\n",
       " 442711.75,\n",
       " 465859.65625,\n",
       " 532312.0625,\n",
       " 532312.0625,\n",
       " 532312.0625,\n",
       " 532312.0625,\n",
       " 532782.8125,\n",
       " 532782.8125,\n",
       " 571312.3125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 589835.125,\n",
       " 920337.5625,\n",
       " 920337.5625,\n",
       " 978123.125,\n",
       " 1048338.5625,\n",
       " 1048338.5625,\n",
       " 1048338.5625,\n",
       " 1048338.5625,\n",
       " 1048338.5625,\n",
       " 1048338.5625,\n",
       " 1139958.25,\n",
       " 1139958.25,\n",
       " 1139958.25,\n",
       " 1139958.25,\n",
       " 1139958.25,\n",
       " 1139958.25,\n",
       " 1139958.25,\n",
       " 1139958.25,\n",
       " 1139958.25,\n",
       " 1139958.25,\n",
       " 1139958.25,\n",
       " 1399590.25,\n",
       " 1399590.25,\n",
       " 1399590.25,\n",
       " 1399590.25,\n",
       " 1399590.25,\n",
       " 1399590.25,\n",
       " 1837485.25,\n",
       " 1837485.25,\n",
       " 1837485.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1887657.25,\n",
       " 1991594.875,\n",
       " 1991594.875,\n",
       " 1992340.125,\n",
       " 1992340.125,\n",
       " 1992340.125,\n",
       " 1992340.125,\n",
       " 1992340.125,\n",
       " 1992340.125,\n",
       " 1992340.125,\n",
       " 1992340.125,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 1993600.75,\n",
       " 2557078.0,\n",
       " 2557078.0,\n",
       " 2557078.0,\n",
       " 3683264.25,\n",
       " 3683264.25,\n",
       " 3683264.25,\n",
       " 3683264.25,\n",
       " 3683264.25,\n",
       " 3683264.25,\n",
       " 3683264.25,\n",
       " 3683264.25,\n",
       " 3683264.25,\n",
       " 3683264.25,\n",
       " 3683264.25]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norms.sort()\n",
    "norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb78a2-ffcc-4cc3-99c1-98b18712c71b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (annotated-transformer)",
   "language": "python",
   "name": "annotated-transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
